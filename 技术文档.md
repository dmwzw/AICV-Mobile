# AICV-Mobile 目标检测与跟踪系统技术文档 (中文)

## 1. 项目概述

AICV-Mobile 是一个基于YOLOv8和改进版OC-SORT算法的目标检测与跟踪系统，专为Android平台设计和优化。本系统实现了高效的目标检测、实例分割及目标跟踪功能，并支持掩码（分割）跟踪，能够实时跟踪目标的形状变化。

### 1.1 核心功能

-   **高效目标检测**：基于YOLOv8模型，支持COCO数据集80类通用物体检测
-   **实例分割**：支持物体的精确分割，生成掩码
-   **目标跟踪**：实现了改进版OC-SORT算法，配合卡尔曼滤波器提高跟踪精度
-   **掩码跟踪**：能够跟踪目标形状变化，支持掩码预测和时间域平滑
-   **多样化显示风格**：支持多种检测框、掩码和轨迹的显示风格
-   **性能优化**：针对移动设备进行了性能优化，禁用C++异常处理

## 2. 系统架构

### 2.1 整体架构

系统采用Java+C++混合开发架构，通过JNI实现两种语言之间的交互：

```
┌─────────────────┐      ┌─────────────────┐
│  Java层 (UI)    │      │  C++层 (算法)    │
│                 │      │                 │
│ - 用户界面      │<────>│ - 模型推理      │
│ - 相机交互      │ JNI  │ - 目标检测      │
│ - 设置管理      │      │ - 目标跟踪      │
└─────────────────┘      └─────────────────┘
```

### 2.2 依赖架构

-   **推理引擎**：NCNN (腾讯开源的神经网络推理框架)
-   **图像处理**：OpenCV Mobile 4.6.0
-   **跟踪算法**：改进版OC-SORT (Observation-Centric SORT) 思想 + Kalman Filter
-   **Android相机**：基于Camera2 API

## 3. 代码结构详解

### 3.1 主要目录结构

```
app/src/main/
├── java/                // Java代码目录
│   ├── com/gyq/        // 主包目录
│   └── ylov/colorpicker// 颜色选择器组件
├── jni/                // C++代码目录
│   ├── yolo.cpp        // YOLO检测实现
│   ├── yolo.h          // YOLO类定义
│   ├── yolov8ncnn.cpp  // JNI接口实现
│   ├── EnhancedTracker.h // 增强版跟踪器
│   ├── OCsort.h        // 基础OC-SORT算法实现
│   ├── Object.h        // 检测对象定义
│   ├── TrackingParams.h // 跟踪参数定义
│   ├── ndkcamera.cpp   // 相机接口实现 (C++)
│   └── ndkcamera.h     // 相机接口定义 (C++)
└── assets/             // 模型文件目录
    └── yolov8*.bin/param // YOLO模型文件
```

### 3.2 核心组件说明

#### 3.2.1 Yolo类 (`yolo.h`)

负责管理目标检测模型并执行推理。

-   功能: 模型加载、检测、分割、参数配置、多数据集支持、结果绘制、掩码处理。
-   关键方法: `load()`, `detect()`, `draw()`, `setDetectionStyle()`。

#### 3.2.2 跟踪系统

1.  **OCSort类** (`OCsort.h`)
    -   实现基础版OC-SORT算法。
    -   使用IoU和质心距离进行关联。
    -   维护ID和生命周期。
2.  **EnhancedTracking类** (`EnhancedTracker.h`)
    -   增强版跟踪器，整合卡尔曼滤波和OC-SORT思想。
    -   支持掩码跟踪。
    -   支持多种跟踪模式和参数配置。
3.  **TrackingParams结构体** (`TrackingParams.h`)
    -   定义丰富的跟踪参数，支持场景优化配置。

#### 3.2.3 Object结构体 (`Object.h`)

表示检测和跟踪的目标对象。

```cpp
struct Object {
    cv::Rect rect;        // 目标边界框
    int label;            // 类别标签
    float prob;           // 置信度
    cv::Mat mask;         // 分割掩码
    std::vector<float> mask_feat; // 掩码特征 (或系数)
    int track_id;         // 跟踪ID
};
```

## 4. 算法详解

### 4.1 目标检测 (YOLOv8)

#### 4.1.1 检测流程

1.  **预处理**: 调整大小、归一化、颜色转换。
2.  **模型推理**: 使用NCNN执行前向推理 (支持GPU)。
3.  **后处理**: 解析输出、NMS、生成检测结果 (框、置信度、类别)。
4.  **掩码处理 (分割模型)**: 解码掩码系数、生成掩码、对齐边界框、阈值化。

### 4.2 目标跟踪 (改进版OC-SORT + Kalman)

#### 4.2.1 跟踪流程

1.  **预测**: 使用卡尔曼滤波预测下一帧位置/状态。
2.  **关联**: 计算预测与检测的代价矩阵 (IoU, 距离, 运动相似性)，贪婪匹配。
3.  **更新**: 使用匹配的检测更新卡尔曼滤波器；未匹配跟踪标记为丢失；未匹配检测创建新轨迹。
4.  **生命周期管理**: 根据命中/丢失次数管理轨迹，删除超时轨迹，确认新轨迹。

#### 4.2.2 掩码跟踪机制

1.  **掩码存储**: 维护最近N帧掩码历史 (及系数)。
2.  **掩码预测**: 目标丢失时，基于运动预测变换 (warpAffine) 掩码。
3.  **掩码平滑**: 时间域加权平均减少抖动，然后二值化。

### 4.3 特殊场景优化

提供多种模式以适应不同场景。

#### 4.3.1 空间分布模式

-   **稀疏**: 目标少且分散。
-   **密集**: 目标密集，保守预测。
-   **超密集**: 极度拥挤，主要依赖观测。

#### 4.3.2 运动模式

-   **静态**: 目标几乎不动。
-   **匀速**: 标准卡尔曼模型。
-   **匀加速**: 考虑加速度。
-   **可变**: 自适应调整模型。
-   **通用**: 平衡模式。

#### 4.3.3 手持模式

-   针对相机移动优化：运动补偿、考虑加速度、调整预测权重。

## 5. 性能优化

### 5.1 推理优化

-   NCNN框架、ARM NEON、Vulkan GPU、模型量化(INT8)。

### 5.2 内存优化

-   内存池、禁用C++异常、共享网络层内存、低精度掩码表示。

### 5.3 算法优化

-   简化跟踪计算、自适应NMS、动态分辨率、批处理。

## 6. 显示风格系统

### 6.1 边界框风格

-   线条、颜色 (单色/类别/ID映射)、透明度。

### 6.2 文本风格

-   多种预设风格 (科技、未来、霓虹、军事、简约)。

### 6.3 掩码风格

-   透明度、对比度、边缘类型、边缘颜色。

### 6.4 轨迹可视化

-   显示轨迹点、配置长度、调整样式 (颜色/粗细)、启用/禁用。

## 7. 系统扩展性

### 7.1 模型扩展

-   易于更换YOLO模型，自动/手动配置。

### 7.2 数据集扩展

-   内置COCO、OIV支持，可自定义类别文件。

### 7.3 算法扩展

-   模块化跟踪设计，参数化配置，易于添加新策略。

## 8. 误差处理机制

因禁用C++异常，采用多层策略：

### 8.1 预防性检查

-   输入有效性、矩阵/变换尺寸、掩码有效性。

### 8.2 容错机制

-   检测失败时依赖跟踪、掩码变换失败时回退、随机扰动防崩溃。

### 8.3 错误日志

-   Android日志系统、分级日志、关键操作记录。

## 9. 系统要求与编译说明

### 9.1 系统要求

-   Android 6.0+ (API 23+)
-   ARMv8 (arm64-v8a)
-   摄像头
-   RAM >= 2GB

### 9.2 编译环境

-   Android Studio 4.0+
-   NDK r21+
-   CMake 3.18+
-   OpenCV Mobile 4.6.0
-   NCNN 20230223+

### 9.3 编译步骤

1.  克隆代码库
2.  在Android Studio中打开项目
3.  同步Gradle
4.  编译安装

## 10. 使用指南

### 10.1 基本操作

1.  启动应用，授权相机
2.  对准目标
3.  自动检测与跟踪 (显示框、类别、置信度、ID、轨迹)

### 10.2 设置选项

-   检测风格
-   掩码阈值
-   启用/禁用跟踪
-   启用/禁用掩码跟踪
-   启用/禁用轨迹显示 (+样式)
-   跟踪模式 (稳定、手持等)

### 10.3 性能调优

-   选小模型 (YOLOv8n)
-   降分辨率
-   调整跟踪参数 (最大年龄、最小命中)

## 11. 未来扩展计划

-   集成新模型 (YOLOv9+)
-   ReID (重识别)
-   多相机联动
-   更多自定义风格
-   优化掩码预测
-   目标行为分析
-   支持更多硬件加速平台

## 12. 故障排除

### 12.1 常见问题

-   崩溃 (内存、模型加载)
-   检测不准 (调模型/阈值)
-   ID切换 (调IoU/跟踪模式)
-   掩码粗糙 (调平滑/阈值)

### 12.2 性能问题

-   低帧率 (小模型、关掩码)
-   高内存 (减掩码历史)
-   高GPU (切CPU、降分辨率)
-   耗电快 (降帧率、高效模型)

## 13. 参考资源

-   YOLO: [https://github.com/ultralytics/ultralytics](https://github.com/ultralytics/ultralytics)
-   OC-SORT Paper: [https://arxiv.org/abs/2203.14360](https://arxiv.org/abs/2203.14360)
-   NCNN: [https://github.com/Tencent/ncnn](https://github.com/Tencent/ncnn)
-   OpenCV: [https://opencv.org/](https://opencv.org/)

---

# AICV-Mobile Object Detection and Tracking System Technical Documentation (English)

## 1. Project Overview

AICV-Mobile is an object detection and tracking system based on YOLOv8 and an improved OC-SORT algorithm, designed and optimized for the Android platform. This system implements efficient object detection, instance segmentation, and object tracking functionalities, including support for mask (segmentation) tracking to follow the shape changes of targets in real-time.

### 1.1 Core Features

-   **Efficient Object Detection**: Based on the YOLOv8 model, supports detection of 80 common object classes from the COCO dataset.
-   **Instance Segmentation**: Supports precise object segmentation to generate masks.
-   **Object Tracking**: Implements an improved OC-SORT algorithm combined with a Kalman filter for enhanced tracking accuracy.
-   **Mask Tracking**: Capable of tracking target shape changes, supporting mask prediction and temporal smoothing.
-   **Diverse Display Styles**: Supports various display styles for bounding boxes, masks, and trajectories.
-   **Performance Optimization**: Optimized for mobile devices, including disabling C++ exception handling.

## 2. System Architecture

### 2.1 Overall Architecture

The system uses a Java+C++ hybrid development architecture, interacting via JNI:

```
┌─────────────────┐      ┌─────────────────┐
│  Java Layer (UI)│      │  C++ Layer (Algo) │
│                 │      │                 │
│ - User Interface│<────>│ - Model Inference │
│ - Camera Interac│ JNI  │ - Object Detection│
│ - Settings Mgmt │      │ - Object Tracking │
└─────────────────┘      └─────────────────┘
```

### 2.2 Dependency Architecture

-   **Inference Engine**: NCNN (Tencent's open-source neural network inference framework)
-   **Image Processing**: OpenCV Mobile 4.6.0
-   **Tracking Algorithm**: Concepts from improved OC-SORT (Observation-Centric SORT) + Kalman Filter
-   **Android Camera**: Based on Camera2 API

## 3. Code Structure Details

### 3.1 Main Directory Structure

```
app/src/main/
├── java/                // Java code directory
│   ├── com/gyq/        // Main package directory
│   └── ylov/colorpicker// Color picker component
├── jni/                // C++ code directory
│   ├── yolo.cpp        // YOLO detection implementation
│   ├── yolo.h          // YOLO class definition
│   ├── yolov8ncnn.cpp  // JNI interface implementation
│   ├── EnhancedTracker.h // Enhanced tracker
│   ├── OCsort.h        // Base OC-SORT algorithm implementation
│   ├── Object.h        // Detection object definition
│   ├── TrackingParams.h // Tracking parameters definition
│   ├── ndkcamera.cpp   // Camera interface implementation (C++)
│   └── ndkcamera.h     // Camera interface definition (C++)
└── assets/             // Model files directory
    └── yolov8*.bin/param // YOLO model files
```

### 3.2 Core Component Descriptions

#### 3.2.1 Yolo Class (`yolo.h`)

Manages the object detection model and performs inference.

-   Functions: Model loading, detection, segmentation, parameter configuration, multi-dataset support, result drawing, mask processing.
-   Key Methods: `load()`, `detect()`, `draw()`, `setDetectionStyle()`.

#### 3.2.2 Tracking System

1.  **OCSort Class** (`OCsort.h`)
    -   Implements the basic OC-SORT algorithm.
    -   Uses IoU and centroid distance for association.
    -   Maintains ID and lifecycle.
2.  **EnhancedTracking Class** (`EnhancedTracker.h`)
    -   Enhanced tracker integrating Kalman filter and OC-SORT concepts.
    -   Supports mask tracking.
    -   Supports multiple tracking modes and parameter configurations.
3.  **TrackingParams Struct** (`TrackingParams.h`)
    -   Defines rich tracking parameters, supporting configuration for scene optimization.

#### 3.2.3 Object Struct (`Object.h`)

Represents detected and tracked target objects.

```cpp
struct Object {
    cv::Rect rect;        // Target bounding box
    int label;            // Class label
    float prob;           // Confidence score
    cv::Mat mask;         // Segmentation mask
    std::vector<float> mask_feat; // Mask features (or coefficients)
    int track_id;         // Tracking ID
};
```

## 4. Algorithm Details

### 4.1 Object Detection (YOLOv8)

#### 4.1.1 Detection Flow

1.  **Preprocessing**: Resize, normalize, color conversion.
2.  **Model Inference**: Perform forward pass using NCNN (GPU supported).
3.  **Postprocessing**: Parse output, apply NMS, generate detection results (boxes, scores, classes).
4.  **Mask Processing (for segmentation models)**: Decode mask coefficients, generate mask, align with bounding box, apply threshold.

### 4.2 Object Tracking (Improved OC-SORT + Kalman)

#### 4.2.1 Tracking Flow

1.  **Predict**: Use Kalman filter to predict the next frame's position/state.
2.  **Associate**: Calculate cost matrix between predictions and detections (IoU, distance, motion similarity), perform greedy matching.
3.  **Update**: Update Kalman filter for matched tracks using detections; mark unmatched tracks as lost; create new tracks for unmatched detections.
4.  **Lifecycle Management**: Manage tracks based on hit/miss counts, delete timed-out tracks, confirm new tracks.

#### 4.2.2 Mask Tracking Mechanism

1.  **Mask Storage**: Maintain history of recent N masks (and coefficients).
2.  **Mask Prediction**: When target is lost, transform the previous mask based on motion prediction (e.g., `warpAffine`).
3.  **Mask Smoothing**: Apply temporal weighted average to reduce jitter, then binarize.

### 4.3 Special Scene Optimization

Provides various modes to adapt to different scenarios.

#### 4.3.1 Spatial Distribution Modes

-   **Sparse**: Few and scattered targets.
-   **Dense**: Dense targets, conservative prediction.
-   **Ultra-Dense**: Extremely crowded, relies heavily on observations.

#### 4.3.2 Motion Modes

-   **Static**: Targets barely move.
-   **Constant Velocity**: Standard Kalman model.
-   **Constant Acceleration**: Considers acceleration.
-   **Variable**: Adaptively adjusts the model.
-   **General**: Balanced default mode.

#### 4.3.3 Handheld Mode

-   Optimization for camera movement: motion compensation, considers acceleration, adjusts prediction weights.

## 5. Performance Optimization

### 5.1 Inference Optimization

-   NCNN framework, ARM NEON, Vulkan GPU, Model Quantization (INT8).

### 5.2 Memory Optimization

-   Memory pool allocator, disabled C++ exceptions, shared network layer memory, low-precision mask representation.

### 5.3 Algorithm Optimization

-   Simplified tracking calculations, adaptive NMS, dynamic resolution, batch processing.

## 6. Display Style System

### 6.1 Bounding Box Styles

-   Line styles, color schemes (single/class/ID mapping), transparency.

### 6.2 Text Styles

-   Multiple preset styles (Tech, Future, Neon, Military, Simple).

### 6.3 Mask Styles

-   Transparency, contrast, edge types, edge colors.

### 6.4 Trajectory Visualization

-   Display trajectory points, configure length, adjust style (color/thickness), enable/disable.

## 7. System Extensibility

### 7.1 Model Extension

-   Easy to swap YOLO models, automatic/manual configuration.

### 7.2 Dataset Extension

-   Built-in COCO, OIV support, customizable class name files.

### 7.3 Algorithm Extension

-   Modular tracking design, parameterized configuration, easy to add new strategies.

## 8. Error Handling Mechanism

Due to disabled C++ exceptions, a multi-layered strategy is used:

### 8.1 Preventative Checks

-   Input validity, matrix/transform dimensions, mask validity.

### 8.2 Fault Tolerance Mechanisms

-   Rely on tracking during detection failure, fallback for mask transformation failure, random perturbation to prevent filter collapse.

### 8.3 Error Logging

-   Android logging system, tiered logging, logging critical operations.

## 9. System Requirements and Compilation Instructions

### 9.1 System Requirements

-   Android 6.0+ (API 23+)
-   ARMv8 (arm64-v8a) architecture
-   Camera
-   RAM >= 2GB

### 9.2 Compilation Environment

-   Android Studio 4.0+
-   NDK r21+
-   CMake 3.18+
-   OpenCV Mobile 4.6.0
-   NCNN 20230223+

### 9.3 Compilation Steps

1.  Clone the repository
2.  Open the project in Android Studio
3.  Sync Gradle
4.  Compile and install

## 10. Usage Guide

### 10.1 Basic Operation

1.  Launch app, grant camera permission
2.  Point at targets
3.  Automatic detection & tracking (shows boxes, class, score, ID, trajectory)

### 10.2 Settings Options

-   Detection/Display Style
-   Mask Threshold
-   Enable/Disable Tracking
-   Enable/Disable Mask Tracking
-   Enable/Disable Trajectory Display (+style)
-   Tracking Mode (Stable, Handheld, etc.)

### 10.3 Performance Tuning

-   Choose smaller models (YOLOv8n)
-   Lower processing resolution
-   Adjust tracking parameters (max age, min hits)

## 11. Future Expansion Plans

-   Integrate newer models (YOLOv9+)
-   Add ReID (Re-identification)
-   Multi-camera cooperative tracking
-   More custom styles
-   Optimize mask prediction
-   Target behavior analysis
-   Support for more hardware acceleration platforms

## 12. Troubleshooting

### 12.1 Common Issues

-   Crashes (Memory, model loading)
-   Inaccurate Detection (Adjust model/threshold)
-   Frequent ID Switches (Adjust IoU/tracking mode)
-   Rough Mask Edges (Adjust smoothing/threshold)

### 12.2 Performance Issues

-   Low FPS (Smaller model, disable mask)
-   High Memory Usage (Reduce mask history)
-   High GPU Usage (Switch to CPU, lower resolution)
-   Fast Battery Drain (Reduce FPS, efficient model)

## 13. Reference Resources

-   YOLO: [https://github.com/ultralytics/ultralytics](https://github.com/ultralytics/ultralytics)
-   OC-SORT Paper: [https://arxiv.org/abs/2203.14360](https://arxiv.org/abs/2203.14360)
-   NCNN: [https://github.com/Tencent/ncnn](https://github.com/Tencent/ncnn)
-   OpenCV: [https://opencv.org/](https://opencv.org/) 